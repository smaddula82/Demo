{"cells":[{"cell_type":"markdown","source":["### Setup the Spark VM and complete the below assignment\n","\n","Objective:- Build a ML model to predict the employee compensation.\n","The application should be modelled using Spark.\n","\n","You can refer to the below links for spark commands:- \n","- https://spark.apache.org/docs/latest/ml-pipeline.html\n","\n","- https://github.com/spark-in-action/first-edition\n","\n","- https://github.com/FavioVazquez/first_spark_model"],"metadata":{"id":"dOMqSrk_Q-xH"}},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2f9c04dd-cf52-4c53-aecd-bfe96f9529af","showTitle":false,"title":""},"id":"lAEn9f14QP0a"},"source":["# Predicting Employee Compensation"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"0ad7374a-5b59-4f1d-9a73-ecdf72f93ffd","showTitle":false,"title":""},"id":"SsDAS5vxQP0c"},"source":["## Data Dictionary\n","<br>**Year Type** - Fiscal (July through June) or Calendar (January through December)\n","<br>**Year** - An accounting period of 12 months. The City and County of San Francisco operates on a fiscal year that begins on July 1 and ends on June 30 the following year. The Fiscal Year ending June 30, 2012 is represented as FY2011-2012.\n","<br>**Organization Group Code** - Org Group is a group of Departments. For example, the Public Protection Org Group includes departments such as the Police,Fire, Adult Probation, District Attorney, and Sheriff.\n","<br> **Organization Group** - Org Group is a group of Departments. For example, the Public Protection Org Group includes departments such as the Police,\n","Fire, Adult Probation, District Attorney, and Sheriff.\n","<br>**Department Code** - Departments are the primary organizational unit used by the Cityand County of San Francisco. Examples include Recreation and\n","Parks, Public Works, and the Police Department.\n","<br>**Department Code** - Departments are the primary organizational unit used by the City and County of San Francisco. Examples include Recreation and Parks, Public Works, and the Police Department.\n","<br>**Union Code** - Unions represent employees in collective bargaining agreements. A job belongs to one union, although some jobs are unrepresented (usually temporarily).\n","<br>**Union** - Unions represent employees in collective bargaining agreements. A job belongs to one union, although some jobs are unrepresented (usually temporarily).\n","<br>**Job Family Code** Job Family combines similar Jobs into meaningful groups.\n","<br>**Job Family** Job Family combines similar Jobs into meaningful groups.\n","<br>**Employee Identifier** Each distinct number in the “Employee Identifier” column represents one employee. These identifying numbers are not meaningful but rather are randomly assigned for the purpose of building this dataset. The column does not appear on the\n","Employee Compensation report hosted on openbook.sfgov.org,\n","but that report does show one row for each employee. Employee\n","ID has been included here to allow users to reconstruct the\n","original report. Note that each employee’s identifier will change\n","each time this dataset is updated, so comparisons by employee\n","across multiple versions of the dataset are not possible.\n","<br>**Salaries** - Normal salaries paid to permanent or temporary City employees.\n","<br>**Overtime** - Amounts paid to City employees working in excess of 40 hours\n","per week.\n","<br>**Other Salaries** - Various irregular payments made to City employees including premium pay, incentive pay, or other one-time payments. Total Salary Number The sum of all salaries paid to City employees.\n","<br>**Retirement** City contributions to employee retirement plans.\n","<br>**Health/Dental** City-paid premiums to health and dental insurance plans covering City employees. To protect confidentiality as legally required, pro-rated citywide averages are presented in lieu of employee-specific health and dental benefits.\n","<br>**Other Benefits** Mandatory benefits paid on behalf of employees, such as Social Security (FICA and Medicare) contributions, unemployment\n","insurance premiums, and minor discretionary benefits not included in the above categories.\n","<br>**Total Benefits** The sum of all benefits paid to City employees.\n","<br>**Total Compensation** The sum of all salaries and benefits paid to City employees."]},{"cell_type":"markdown","metadata":{"id":"v_3QapC-QP0d"},"source":["Read the data and answer the following questions to predict employee compensation"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ffb92bbb-6e3b-46ec-885e-bb4471538c0c","showTitle":false,"title":""},"id":"_nMVTM8BQP0d"},"source":["## 1. Read the Data"]},{"cell_type":"code","source":[""],"metadata":{"id":"PW5bNl6qRY4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"oKyTtwSqRY7b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.1 Display the number of rows and columns in the dataset"],"metadata":{"id":"aWQ3YZi0RdP_"}},{"cell_type":"code","source":[""],"metadata":{"id":"hdbFw58TRjQd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2 Check the datatype of the variables"],"metadata":{"id":"cZYaCB4cRjjg"}},{"cell_type":"code","source":[""],"metadata":{"id":"jdPpc_mgRpva"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"re0TB8PAQP0f"},"source":["### 2. Convert the incorrect column type into its suitable column type. And drop the redundant features"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"173LNkp7QP0f"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"28154731-5e40-46a7-b9b3-9444c20c97e8","showTitle":false,"title":""},"id":"LYYQFu0dQP0g"},"source":["### 3. Check basic statistics and perform necessary data preprocessing (Like removing negative amount)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"DbrJKqGqQP0g"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5b4a36b1-7f14-4a99-851e-492fd8ebb193","showTitle":false,"title":""},"id":"woI-NVRxQP0g"},"source":["### 4. Perform Missing Value Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"T7kTJJ_QQP0g"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9cd43cd2-ed88-4edf-ba6f-7e7e6f2f65d1","showTitle":false,"title":""},"id":"K_KbHnjZQP0g"},"source":["### 5. Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"44aa560c-5c6a-4188-a740-5e49cd147b26","showTitle":false,"title":""},"id":"5hea56hUQP0h"},"source":["#### 5.1. Find top compensating organizations. Display using bar plot"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"kpaIAoMQQP0h"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c991e941-045b-4556-ba17-f9c5454fdf06","showTitle":false,"title":""},"id":"hijeAEfXQP0h"},"source":["#### 5.2. Find top Compensating Jobs. Display using bar plot"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"AmdpJh5vQP0h"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1ffac626-b0f9-45f4-b780-c1c06edf6dd1","showTitle":false,"title":""},"id":"txsSQSvNQP0h"},"source":["#### 5.3. Check Correlation of Target Variable with Other Independent Variables. Plot Heatmap"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"NFo9Q21lQP0h"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9f43beda-e255-4431-a35a-bb05a1f1e670","showTitle":false,"title":""},"id":"NiZX_Be8QP0h"},"source":["### 6. Perform necessary data pre-processing and divide the data into train and test set"]},{"cell_type":"markdown","source":["### 6.1 Categorise the attributes into its type (Use one hot encoding wherever required)"],"metadata":{"id":"6p5egOcB-VnG"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"O5SYln1OQP0i"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["### 6.2 Split the data into train and test set"],"metadata":{"id":"rrGRAFAG-YLX"}},{"cell_type":"code","source":[""],"metadata":{"id":"K7phDDJU-sav"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"114ba72f-16e5-4657-bbaf-969596890cca","showTitle":false,"title":""},"id":"XSZnLJe5QP0i"},"source":["### 7. Fit Linear Regression model on the data and check its performance"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"bjXSlK7OQP0i"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"51e30540-ef2e-4239-b323-ba406674e87b","showTitle":false,"title":""},"id":"yb53Fy9yQP0i"},"source":["### 8. Fit Decision Tree Regression model on the data and check its performance (Optional)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"XVl80s2AQP0i"},"outputs":[],"source":["from pyspark.ml.regression import DecisionTreeRegressor\n","dt = DecisionTreeRegressor(featuresCol ='scaled_features', labelCol = 'Total Compensation')\n","dt_model = dt.fit(trainDF)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"addb469a-37a3-47e8-8e65-4972a889cc4f","showTitle":false,"title":""},"id":"NPagi7ftQP0i"},"source":["### Model Persistence (Optional)\n","Model persistence means saving your model to a disk. After you finalize your model for prediction depending upon the performance, you need to save the model to the disk. Let's say, you finalize 'lrmodel' to be used for in production environment i.e. in your application. We use the following code to save it."]},{"cell_type":"markdown","source":["##### Saving the model"],"metadata":{"id":"Id1_cG1yb_7n"}},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"be6d56cb-e99e-4b37-993b-ef66c9bf7963","showTitle":false,"title":""},"id":"VHHfHnTgQP0i","outputId":"abf31351-bbb5-4a5f-ced2-6b705a4825e2"},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["# use save() method to save the model\n","# write().overwrite() is usually used when you want to replace the older model with a new one\n","# It might happen that you wish to retrain your model and save it at the same the place\n","lrmodel.write().overwrite().save(\"/FileStore/models/lrmodel\")"]},{"cell_type":"markdown","source":["##### Loading the model"],"metadata":{"id":"VzsuP83tcEVN"}},{"cell_type":"code","source":["# import PipelineModel from pyspark.ml package\n","from pyspark.ml import PipelineModel\n","\n","# load the model from the location it is stored\n","# The loaded model acts as PipelineModel\n","pipemodel = PipelineModel.load(\"/FileStore/models/lrmodel\")\n","\n","# use the PipelineModel object to perform prediciton on test data. \n","# Use .transform() to perfrom prediction\n","prediction = pipemodel.transform(testDF)\n","\n","# print the results\n","prediction.select('label', 'rawPrediction', 'probability', 'prediction').show(5)"],"metadata":{"id":"273mlbIPb8rY"},"execution_count":null,"outputs":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"In-Class Exercise (Spark ML)","notebookOrigID":3796726700441172,"widgets":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"Part-2 Question Notebook-.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}