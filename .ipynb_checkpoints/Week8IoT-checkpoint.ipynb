{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836316c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import DataFrame, SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66fdeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/09 18:07:45 WARN Utils: Your hostname, subbu resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/02/09 18:07:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/09 18:07:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>IoT Analysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc1004f5420>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating spark session\n",
    "spark = SparkSession \\\n",
    "       .builder \\\n",
    "       .appName(\"IoT Analysis\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a2a0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Read the data into a Dataframe.\n",
    "df=spark.read.json(\"iot_devices.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8494905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the Dataframe into a temporary view called iot.\n",
    "df.createOrReplaceTempView(\"iot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef986e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|battery_level|c02_level|cca2|cca3|cn           |device_id|device_name          |humidity|ip           |latitude|lcd   |longitude|scale  |temp|timestamp    |\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|8            |868      |US  |USA |United States|1        |meter-gauge-1xbYRYcj |51      |68.161.225.1 |38.0    |green |-97.0    |Celsius|34  |1458444054093|\n",
      "|7            |1473     |NO  |NOR |Norway       |2        |sensor-pad-2n2Pea    |70      |213.161.254.1|62.47   |red   |6.15     |Celsius|11  |1458444054119|\n",
      "|2            |1556     |IT  |ITA |Italy        |3        |device-mac-36TWSKiT  |44      |88.36.5.1    |42.83   |red   |12.83    |Celsius|19  |1458444054120|\n",
      "|6            |1080     |US  |USA |United States|4        |sensor-pad-4mzWkz    |32      |66.39.173.154|44.06   |yellow|-121.32  |Celsius|28  |1458444054121|\n",
      "|4            |931      |PH  |PHL |Philippines  |5        |therm-stick-5gimpUrBB|62      |203.82.41.9  |14.58   |green |120.97   |Celsius|25  |1458444054122|\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#selecting the data from iot view\n",
    "spark.sql(\"select * from iot\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d705c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|device_id|cca3|\n",
      "+---------+----+\n",
      "|    70405| USA|\n",
      "|    14455| CHN|\n",
      "|    12100| JPN|\n",
      "|    11879| KOR|\n",
      "|     7942| DEU|\n",
      "|     6486| GBR|\n",
      "|     6041| CAN|\n",
      "|     5989| RUS|\n",
      "|     5305| FRA|\n",
      "|     3224| BRA|\n",
      "|     3119| AUS|\n",
      "|     2915| ITA|\n",
      "|     2880| SWE|\n",
      "|     2744| POL|\n",
      "|     2488| NLD|\n",
      "|     2310| ESP|\n",
      "|     2128| TWN|\n",
      "|     1867| IND|\n",
      "|     1507| CZE|\n",
      "|     1487| NOR|\n",
      "+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Count how many devices are there from each country and display the output.\n",
    "spark.sql(\"select count(distinct device_id) as device_id,cca3 from iot group by cca3 order by device_id desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b0441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|cca3|c02_level|\n",
      "+----+---------+\n",
      "| BGR|     1599|\n",
      "| USA|     1599|\n",
      "| EGY|     1599|\n",
      "| TWN|     1599|\n",
      "| DEU|     1599|\n",
      "| DEU|     1599|\n",
      "| CAN|     1599|\n",
      "| JPN|     1599|\n",
      "| DEU|     1599|\n",
      "| BGR|     1599|\n",
      "| ARG|     1599|\n",
      "| GBR|     1599|\n",
      "| USA|     1599|\n",
      "| USA|     1599|\n",
      "| USA|     1599|\n",
      "| CHN|     1599|\n",
      "| KOR|     1599|\n",
      "| USA|     1599|\n",
      "| NOR|     1599|\n",
      "| POL|     1599|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Display all the countries whose carbon dioxide level is more than 1400. Sort the output in descending order.\n",
    "spark.sql(\"select cca3, c02_level from iot where c02_level > 1400 order by c02_level desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9972ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|cca3|device_id|\n",
      "+----+---------+\n",
      "| USA|    17489|\n",
      "| CHN|     3616|\n",
      "| KOR|     2942|\n",
      "| JPN|     2935|\n",
      "| DEU|     1966|\n",
      "| GBR|     1660|\n",
      "| CAN|     1564|\n",
      "| RUS|     1508|\n",
      "| FRA|     1353|\n",
      "| BRA|      856|\n",
      "| AUS|      769|\n",
      "| SWE|      724|\n",
      "| ITA|      713|\n",
      "| POL|      664|\n",
      "| NLD|      646|\n",
      "| ESP|      586|\n",
      "| TWN|      542|\n",
      "| IND|      446|\n",
      "| NOR|      399|\n",
      "| UKR|      373|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Select all countries' devices with high-levels of C02 and group by cca3 and order by device_ids (Hint: For high CO2 level, the LCD status will be RED).\n",
    "spark.sql(\"select cca3, count(distinct device_id) as device_id from iot where lcd == 'red' group by cca3 order by device_id desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc2d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|cca3|device_id|\n",
      "+----+---------+\n",
      "| USA|     7043|\n",
      "| CHN|     1415|\n",
      "| KOR|     1217|\n",
      "| JPN|     1210|\n",
      "| DEU|      760|\n",
      "| GBR|      650|\n",
      "| CAN|      612|\n",
      "| RUS|      600|\n",
      "| FRA|      582|\n",
      "| BRA|      374|\n",
      "| AUS|      322|\n",
      "| SWE|      293|\n",
      "| ITA|      287|\n",
      "| POL|      278|\n",
      "| NLD|      251|\n",
      "| ESP|      223|\n",
      "| TWN|      207|\n",
      "| IND|      189|\n",
      "| UKR|      149|\n",
      "| HKG|      149|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#find out all devices in countries whose batteries need replacements.Assuming battery level 0 means need replacement\n",
    "spark.sql(\"select cca3, count(distinct device_id) as device_id from iot where battery_level == 0 group by cca3 order by device_id desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb76ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
